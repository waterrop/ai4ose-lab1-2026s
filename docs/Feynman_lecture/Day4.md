# 从批处理到分时：任务切换与上下文保存的最小闭环

批处理系统是串行执行任务的，即这个任务执行完才能执行下一个任务，这就会导致一个问题——当现在在执行的任务请求I/O时，并没有使用CPU，这时候CPU就是空闲状态，会导致CPU的浪费，所以有没有一种办法可以让任务不用CPU的时候让出CPU让其他任务执行呢？——这就是任务调度。

确定了任务调度后，又出现了新的问题：
1. 什么时候进行任务调度呢？
2. 让出CPU后，如何选择下一个该执行的任务呢？

## 一、什么时候进行任务调度呢？

有两个选择的方式，一是时钟中断方式，也就是抢占式调度；二是任务主动让出CPU，也就是协作式调度。

## 二、让出CPU后，如何选择下一个该执行的任务呢？

有很多调度算法，比如先来先服务、短作业优先、优先级等。

## 三、如何实现任务调度？

想实现任务调度，就需要更好的管理任务，所以我们定义一个任务控制块（Task Control Block, TCB）用来管理任务，TCB是内核管理任务的核心数据结构。
在 tg-ch3 中，每个 TCB 包含：
```
| 字段 | 类型 | 说明 |
|------|------|------|
| `ctx` | `LocalContext` | 用户态上下文（所有通用寄存器 + CSR） |
| `finish` | `bool` | 任务是否已完成 |
| `stack` | `[usize; 1024]` | 独立的用户栈（8 KiB） |
```

- Trap 上下文与任务上下文区别

- trace 如何帮助观测系统调用行为

- 典型 bug 与排查

# AI
大家好，今天我们来聊聊操作系统是如何从“批处理”进化到“分时”的，重点理解任务切换和上下文保存的核心思想。

1. 批处理的问题
早期的批处理系统只能串行执行任务——一个任务执行完，才能执行下一个。
假设任务A正在计算，突然需要读取磁盘数据（I/O操作），这时CPU只能干等着，因为A暂时用不到CPU，但系统又不允许其他任务运行。这就造成了CPU资源的浪费。

2. 引入任务调度
怎么解决呢？很简单：当任务不用CPU时，让它主动或被动地让出CPU，让其他任务运行。这就是任务调度。
但调度需要回答两个关键问题：

什么时候切换？

一种是抢占式调度：靠时钟中断强行打断当前任务，强制切换（比如每个时间片到了就切换）。

另一种是协作式调度：任务自己主动调用yield让出CPU（比如等待I/O时）。

切换给谁？
这就涉及调度算法，比如先来先服务、短作业优先、优先级调度等。算法决定哪个任务下一个运行。

3. 如何实现任务调度？
光有决策还不够，系统必须能“记住”每个任务执行到哪了，下次切换回来时才能继续。这就需要保存任务的执行状态——也就是上下文，包括程序计数器（PC）、通用寄存器、栈指针等。

为此，操作系统为每个任务创建一个任务控制块（TCB），就像任务的身份证，里面存着：

上下文（ctx）：保存CPU寄存器的值，切换时存入，恢复时读出。

栈（stack）：每个任务有自己的独立栈，避免互相干扰。

完成标志（finish）：标记任务是否已结束。

有了TCB，调度器就可以在切换时：

把当前任务的寄存器值保存到它的TCB.ctx中；

从下一个任务的TCB.ctx中恢复寄存器的值；

跳转到新任务上次执行的位置继续运行。

4. 一点小补充
在实现中，我们会遇到两种上下文：

Trap上下文：通常是任务陷入内核（比如系统调用或中断）时保存的完整寄存器状态，用于内核处理完后返回用户态。

任务上下文：特指任务切换时保存的寄存器子集，只包含切换必需的寄存器。

理解它们的区别，有助于调试和优化。另外，通过追踪系统调用（trace）可以观察任务的行为，帮助定位bug。

5. 实现系统调用计数：位置设计的权衡
有时我们需要统计每个系统调用的次数，比如测试覆盖率或性能分析。这看似简单：在每次系统调用发生时加1。
但问题是：计数代码应该放在哪里？ 有两个主要选择：

放在用户态库中（如用户程序调用read()时先计数再陷入内核）：

优点：实现简单，不涉及内核修改，计数完全在用户空间。

缺点：如果用户程序直接通过ecall陷入内核（绕过库），计数会被跳过；另外，多线程环境下用户态计数需要同步，容易出错。

放在内核的 trap 处理路径中（在进入系统调用服务例程前后计数）：

优点：所有系统调用都会被捕获，计数准确；集中管理，易于维护。

缺点：内核路径增加额外操作，可能影响性能；需要注意在系统调用失败或提前返回时计数逻辑是否正确。

实际项目中，通常选择在内核中计数，因为准确性更重要。但需要谨慎选择计数点：

如果在进入系统调用前计数，那么即使后续参数检查失败（无效指针等），也会计入一次调用，可能导致统计偏差。

如果在系统调用成功返回后计数，则可以避免无效调用被统计，但可能漏掉某些不返回的调用（如SYS_EXIT），需要特殊处理。

6. 常见错误：计数时机错误导致测试偏差
假设我们要测试一个任务的系统调用次数是否符合预期，比如任务应该执行3次SYS_READ。
如果我们将计数代码放在 trap 处理的入口处（刚识别出系统调用号，尚未进行参数检查），那么当用户程序传入一个无效的文件描述符时，内核可能直接返回错误，但计数已经+1。这样任务实际只成功执行了2次读取，但计数却显示3次，导致测试误判。

另一个例子：任务可能因为信号或中断被提前唤醒，但尚未完成系统调用，如果此时计数，也会产生偏差。
正确的做法是：在系统调用服务例程真正开始执行且确定会执行后计数（比如在函数开头），或者在返回用户态之前根据结果决定是否计数。对于SYS_EXIT这类不返回的调用，可以在执行退出操作前计数。

在实验中，我们经常遇到类似的陷阱，所以写 trace 或计数功能时，一定要仔细思考“什么才算一次有效的系统调用”。

7. 总结
从批处理的串行到分时的并发，核心就是任务调度 + 上下文保存。TCB作为管理任务的数据结构，配合上下文切换机制，构成了任务调度的最小闭环。这为现代操作系统实现多任务、分时共享CPU打下了基础。

好了，今天的分享就到这里，谢谢大家！